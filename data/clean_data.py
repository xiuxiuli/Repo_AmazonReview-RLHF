def clean_text(text: str):
    if not isinstance(text, str):
        return ""
    text = re.sub(r"<.*?>", " ", text)                 # åŽ»é™¤HTMLæ ‡ç­¾
    text = re.sub(r"http\S+|www\S+", " ", text)        # åŽ»é™¤URL
    text = re.sub(r"\s+", " ", text)                   # å¤šä½™ç©ºæ ¼
    text = re.sub(r"[^\x00-\x7F]+", " ", text)         # éžæ‰“å°å­—ç¬¦
    text = text.strip()                                # åŽ»é™¤é¦–å°¾ç©ºæ ¼
    return text

def clean(json){

    # 2. conver to df
    df = raw_data.to_pandas()
    print(f"Loaded {len(df):,} rows.")

    # 3. rename fileds
    # df = df[["review", "title"]]
    df = df.rename(columns={"review": "review", "title": "summary"})

    # 4. remove too long/too short content
    df = df[df["review"].str.len() > 50]
    df = df[df["summary"].str.len().between(10, 200)]

    #print(df["summary"].str.len().describe())

    # 4. remove non-info summary
    bad_summaries = ["good", "ok", "nice", "great", "bad", "fine", "yes"]
    df = df[~df["summary"].str.lower().isin(bad_summaries)]

    # 4. remove other
    df["review"] = df["review"].apply(clean_text)
    df["summary"] = df["summary"].apply(clean_text)

    print(f"âœ… After cleaning: {len(df):,} samples remaining.")
    # ç»Ÿè®¡
    print("\nðŸ“Š Dataset overview:")
    print(f"Total samples after cleaning: {len(df):,}")
    print(f"Average review length: {df['review'].str.len().mean():.1f}")
    print(f"Average summary length: {df['summary'].str.len().mean():.1f}")

    # ðŸ”¹ å­—ç¬¦é•¿åº¦åˆ†å¸ƒ
    print("\nðŸ“ˆ Review length stats:")
    print(df["review"].str.len().describe())

    print("\nðŸ“ˆ Summary length stats:")
    print(df["summary"].str.len().describe())

    if save_jsonl:
        os.makedirs("data/processed", exist_ok=True)
        output_path = "data/processed/sft_train_cleaned.jsonl"
        df.to_json(output_path, orient="records", lines=True, force_ascii=False)
        print(f"âœ… Saved cleaned dataset to: {output_path}")
    return df
}