# =============================
# global paths
# =============================
dataset:
  name: "sentence-transformers/amazon-reviews"
  split: "train"
  size: 400000
  output_subdir: "data/raw"
  output_file: "data/amazon_review_subset.jsonl.gz"
  num_log_steps: 1000000
  seed: 42

cleaning:
  source_file: "data/raw/amazon_review_subset.jsonl.gz"
  output_subdir: "data/processed"
  output_file: "amazon_review_subset_cleaned.jsonl"
  min_review_length: 16
  min_summary_length: 6
  max_summary_length: 60
  bad_summaries: ["good", "ok", "nice", "great", "bad", "fine", "yes"]

partition:
  source_file: "data/processed/amazon_review_subset_cleaned.jsonl"
  output_subdir: "data/split"
  seed: 42
  split_ratio:
    train: 0.8
    val: 0.1
    test: 0.1
  out_files:
    train: "train.jsonl"
    val: "val.jsonl"
    test: "test.jsonl"

train_subset:
  source_file: "data/split/train.jsonl"
  output_subdir: "data/split"
  seed: 42
  subsets:
    - name: "20k"
      size: 20000
      out_file: "train_20k.jsonl"
    - name: "50k"
      size: 50000
      out_file: "train_50k.jsonl"
    - name: "100k"
      size: 100000
      out_file: "train_100k.jsonl"