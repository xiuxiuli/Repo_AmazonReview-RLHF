# ğŸ¤– Repo_AmazonReview-RLHF

**Amazon Product Review Summarization** project built with  
**Supervised Fine-Tuning (SFT)** â†’ **Direct Preference Optimization (DPO)** â†’ **Reinforcement Learning from Human Feedback (RLHF)**.

---

## ğŸ§© Project Overview

This project explores how to generate high-quality summaries from Amazon product reviews.  
Starting from a baseline summarization model (BART / LLaMA-2), it progressively improves alignment with human preference through DPO and RLHF.

---

## ğŸš€ Workflow

| Phase | Objective | Input / Output | Core Tool |
|-------|------------|----------------|-----------|
| **0. Data Preparation** | Load & clean `sentence-transformers/amazon-reviews` dataset | `{review, summary}` | ğŸ¤– `datasets`, `pandas` |
| **1. SFT (Supervised Fine-Tuning)** | Train baseline summarizer (`review â†’ title`) | `Trainer` + ROUGE eval | ğŸ§  `transformers` |
| **2. DPO (Preference Alignment)** | Fine-tune using preference pairs `{prompt, chosen, rejected}` | Align model behavior | âš–ï¸ `trl.DPOTrainer` |
| **3. RLHF (Reward Optimization)** | Train with reward scores via PPO | `{query, response, reward}` | ğŸ® `trl.PPOTrainer` |
| **4. Evaluation & Demo** | Human evaluation + Gradio demo | Generated summaries | ğŸ’¬ `gradio` |

---

## ğŸ“š Dataset

> [`sentence-transformers/amazon-reviews`](https://huggingface.co/datasets/sentence-transformers/amazon-reviews)

| Field | Description |
|-------|--------------|
| `review` | Full text of the product review |
| `title`  | Short user-written title used as summary (training label) |

---

## ğŸ§  Model Stack

- **Base Models:** `facebook/bart-base`, `google/pegasus-small`, or `meta-llama/Llama-2-7b-chat`
- **Training:** `HuggingFace Transformers` + `TRL` + `Accelerate`
- **Quantization:** `BitsAndBytes (4-bit / 8-bit)`
- **Evaluation:** `ROUGE`, `BERTScore`
- **Demo:** `Gradio` / `Streamlit`

---

## ğŸ—‚ï¸ Folder Structure
Repo_AmazonReview-RLHF/
â”œâ”€â”€ data/
â”‚ â”œâ”€â”€ raw/ # Original HuggingFace data
â”‚ â”œâ”€â”€ processed/ # Cleaned CSVs (review-summary pairs)
â”‚ â””â”€â”€ samples/ # Mini subsets for quick tests
â”œâ”€â”€ notebooks/
â”‚ â”œâ”€â”€ phase0_data_preparation.ipynb
â”‚ â”œâ”€â”€ phase1_sft_training.ipynb
â”‚ â”œâ”€â”€ phase2_dpo_training.ipynb
â”‚ â”œâ”€â”€ phase3_rlhf_training.ipynb
â”‚ â””â”€â”€ phase4_evaluation_demo.ipynb
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ data_cleaning.py
â”‚ â”œâ”€â”€ train_sft.py
â”‚ â”œâ”€â”€ train_dpo.py
â”‚ â”œâ”€â”€ train_rlhf.py
â”‚ â””â”€â”€ evaluate.py
â”œâ”€â”€ reports/
â”‚ â”œâ”€â”€ evaluation.md
â”‚ â”œâ”€â”€ summary_examples.md
â”‚ â””â”€â”€ results/
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
